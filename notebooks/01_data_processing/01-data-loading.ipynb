{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Loading\n",
    "---\n",
    "\n",
    "### Notebook Summary:\n",
    "\n",
    "In this notebook, I will perform data pre-processing on a dataset of sign-language images sourced from OpenML.\n",
    "\n",
    "#### Key Steps:\n",
    "- **Data Extraction**: Load the sign-language dataset from OpenML.\n",
    "- **Data Cleaning**: Deal with discontinuity in the target variable.\n",
    "- **Separate out X (features) and y (target)**: Store the pixel data (features) in varaible X and labels in variable y.\n",
    "- **Data Storage**: Save X and y into pickle files for easy use in other notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simybasra/anaconda3/lib/python3.11/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Accessing mnist american sign language dataset\n",
    "#TODO: update to data folder\n",
    "data_path = \"data/mnist\"\n",
    "mnist = fetch_openml('SignMNIST', data_home=data_path, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_image shape: (34627, 28, 28)\n",
      "my_class shape: (34627,)\n"
     ]
    }
   ],
   "source": [
    "#Â Setting class (target) variable -> indicies of alphabet, casting these datatype from a float to int \n",
    "my_class = mnist.target.astype(np.int32)\n",
    "\n",
    "# Accessing image data -> reshape is necessary to 3d array (num_images, pixels_height, pixels_width)\n",
    "# We know each image is 28 by 28 pixels, passing -1 to allow numpy to auto calculate num of images in the dataset\n",
    "my_image= mnist.data.reshape(-1,28,28)\n",
    "\n",
    "# Sanity checking on shapes\n",
    "print('my_image shape:', my_image.shape)\n",
    "print('my_class shape:',my_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping of target variable to remove discontinuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(my_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Comment: The elements in the array are not continuous, we are missing 9 from the list. When we use neueal networks later in the project this will be problematic as we will get an extra node in our output layer for '9'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping to avoid the 'skip' in y\n",
    "mapping = {0:0,\n",
    "           1:1,\n",
    "           2:2,\n",
    "           3:3,\n",
    "           4:4,\n",
    "           5:5,\n",
    "           6:6,\n",
    "           7:7,\n",
    "           8:8,\n",
    "           10:9,\n",
    "           11:10,\n",
    "           12:11,\n",
    "           13:12,\n",
    "           14:13,\n",
    "           15:14,\n",
    "           16:15,\n",
    "           17:16,\n",
    "           18:17,\n",
    "           19:18,\n",
    "           20:19,\n",
    "           21:20,\n",
    "           22:21,\n",
    "           23:22,\n",
    "           24:23\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_target_df = pd.DataFrame(my_class, columns=['mnist_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df and using .map to fix y\n",
    "my_target_df['new_target'] = my_target_df['mnist_target'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking new target var is unique\n",
    "np.unique(my_target_df['new_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening each image back to 784 pixels for the Logistic Regression model\n",
    "flattened_dataset = my_image.reshape(my_image.shape[0],28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = flattened_dataset\n",
    "y = np.array(my_target_df['new_target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pikling X and y to be used for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../model/my_files/y.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# storing data in my_files\n",
    "#TODO: save to data folder as pkl file\n",
    "joblib.dump(X, '../../model/my_files/X.pkl' )\n",
    "joblib.dump(y, '../../model/my_files/y.pkl' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing pikling was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  = joblib.load( '../../model/my_files/X.pkl' )             \n",
    "test_y = joblib.load( '../../model/my_files/y.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34627,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34627,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
